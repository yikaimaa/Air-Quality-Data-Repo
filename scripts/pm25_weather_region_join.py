# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1748mTpxQchQMIEhr5KY4x0JND0qtuQhh
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import pandas as pd


PM25_DEFAULT = "pm25_daily_region.csv"
WEATHER_DEFAULT = "ON_weather_daily_merged_2020-2025_with_region.csv"


# Weather columns aggregation rules when collapsing to (region, date)
WEATHER_AGG = {
    # temps / degree days: mean across stations in the region for that day
    "max_temp_degc": "mean",
    "min_temp_degc": "mean",
    "mean_temp_degc": "mean",
    "heat_deg_days_degc": "mean",
    "cool_deg_days_degc": "mean",

    # precip: mean across stations (avoids "more stations => larger sum" artifact)
    "total_rain_mm": "mean",
    "total_snow_cm": "mean",
    "total_precip_mm": "mean",
    "snow_on_grnd_cm": "mean",

    # gust: max as "worst case" within region-day
    "spd_of_max_gust_km_h": "max",

    # wind direction is circular; mean is a rough placeholder (ok to drop if you want)
    "dir_of_max_gust_deg": "mean",
}


def _standardize_date(df: pd.DataFrame, col: str) -> pd.DataFrame:
    out = df.copy()
    out[col] = pd.to_datetime(out[col], errors="coerce").dt.date
    return out


def main(pm25_path: str, weather_path: str, out_path: str) -> None:
    pm25_path = Path(pm25_path)
    weather_path = Path(weather_path)
    out_path = Path(out_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # --- load ---
    pm = pd.read_csv(pm25_path)
    wx = pd.read_csv(weather_path)

    # --- standardize key columns: region + date ---
    # allow pm25 to have "Date" instead of "date"
    if "Date" in pm.columns and "date" not in pm.columns:
        pm = pm.rename(columns={"Date": "date"})

    required_pm = {"region", "date"}
    required_wx = {"region", "date"}
    if not required_pm.issubset(pm.columns):
        raise ValueError(f"pm25 missing required columns: {required_pm - set(pm.columns)}")
    if not required_wx.issubset(wx.columns):
        raise ValueError(f"weather missing required columns: {required_wx - set(wx.columns)}")

    pm["region"] = pm["region"].astype(str).str.strip()
    wx["region"] = wx["region"].astype(str).str.strip()

    pm = _standardize_date(pm, "date")
    wx = _standardize_date(wx, "date")

    pm = pm.dropna(subset=["region", "date"])
    wx = wx.dropna(subset=["region", "date"])

    # --- weather -> 1 row per (region, date) ---
    agg = {k: v for k, v in WEATHER_AGG.items() if k in wx.columns}

    wx_region_day = (
        wx.groupby(["region", "date"], as_index=False)
          .agg(agg)
    )

    # optional: count unique weather stations contributing to each region-day
    if "station_id" in wx.columns:
        wx_station_n = (
            wx.groupby(["region", "date"], as_index=False)["station_id"]
              .nunique()
              .rename(columns={"station_id": "n_weather_stations"})
        )
        wx_region_day = wx_region_day.merge(wx_station_n, on=["region", "date"], how="left")

    # --- inner join: drop non-matching keys ---
    merged = pm.merge(wx_region_day, on=["region", "date"], how="inner")

    # --- sanity check: should be 1 row per (region, date) ---
    dup = merged.duplicated(subset=["region", "date"]).sum()
    if dup:
        raise ValueError(
            f"Joined data has duplicate (region, date) keys: {dup}. "
            f"Weather likely wasn't fully aggregated to region-day."
        )

    merged.to_csv(out_path, index=False)

    print("âœ… Done")
    print(f"PM25 rows:           {len(pm):,}")
    print(f"Weather region-day:  {len(wx_region_day):,}")
    print(f"Joined rows (inner): {len(merged):,}")
    print(f"Output -> {out_path}")


if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Join PM2.5 daily + Weather daily by (region, date) with inner join.")
    ap.add_argument("--pm25", default=PM25_DEFAULT, help="pm25 daily region csv path")
    ap.add_argument("--weather", default=WEATHER_DEFAULT, help="weather daily merged csv path")
    ap.add_argument("--out", default="outputs/pm25_weather_daily_region_joined.csv", help="output csv path")

    # IMPORTANT: parse_known_args() makes this runnable inside Colab/Jupyter (ignores -f kernel.json)
    args, _ = ap.parse_known_args()

    main(args.pm25, args.weather, args.out)